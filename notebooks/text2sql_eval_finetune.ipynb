{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Core Libraries ---\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# --- Hugging Face: Dataset, Tokenizer, Model ---\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    TrainingArguments, \n",
    "    Trainer, \n",
    "    DataCollatorForLanguageModeling,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "# --- LoRA & Parameter-Efficient Tuning ---\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "\n",
    "# --- W&B Experiment Tracking ---\n",
    "import wandb\n",
    "\n",
    "# --- SQL Evaluation ---\n",
    "import sqlite3\n",
    "import sqlparse\n",
    "from tabulate import tabulate\n",
    "import evaluate  # for BLEU, ROUGE\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "Using GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"GPU not detected — will fall back to CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>response</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89664</th>\n",
       "      <td>what country has more aircraft listed than any...</td>\n",
       "      <td>CREATE TABLE table_204_710 (\\n    id number,\\n...</td>\n",
       "      <td>SELECT \"origin\" FROM table_204_710 GROUP BY \"o...</td>\n",
       "      <td>squall</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166686</th>\n",
       "      <td>For those records from the products and each p...</td>\n",
       "      <td>CREATE TABLE Manufacturers (\\n    Code INTEGER...</td>\n",
       "      <td>SELECT T1.Name, T1.Manufacturer FROM Products ...</td>\n",
       "      <td>nvbench</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243193</th>\n",
       "      <td>What result has mario &amp; karina as the couple?</td>\n",
       "      <td>CREATE TABLE table_name_76 (\\n    result VARCH...</td>\n",
       "      <td>SELECT result FROM table_name_76 WHERE couple ...</td>\n",
       "      <td>sql_create_context</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254344</th>\n",
       "      <td>Which publishers did not publish a book in 1989?</td>\n",
       "      <td>CREATE TABLE culture_company (\\n    company_na...</td>\n",
       "      <td>SELECT publisher FROM book_club EXCEPT SELECT ...</td>\n",
       "      <td>spider</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101637</th>\n",
       "      <td>How many Ratings did the 2013 Year have?</td>\n",
       "      <td>CREATE TABLE table_78359 (\\n    \"Year\" real,\\n...</td>\n",
       "      <td>SELECT \"Ratings\" FROM table_78359 WHERE \"Year\"...</td>\n",
       "      <td>wikisql</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              instruction  \\\n",
       "89664   what country has more aircraft listed than any...   \n",
       "166686  For those records from the products and each p...   \n",
       "243193      What result has mario & karina as the couple?   \n",
       "254344   Which publishers did not publish a book in 1989?   \n",
       "101637           How many Ratings did the 2013 Year have?   \n",
       "\n",
       "                                                    input  \\\n",
       "89664   CREATE TABLE table_204_710 (\\n    id number,\\n...   \n",
       "166686  CREATE TABLE Manufacturers (\\n    Code INTEGER...   \n",
       "243193  CREATE TABLE table_name_76 (\\n    result VARCH...   \n",
       "254344  CREATE TABLE culture_company (\\n    company_na...   \n",
       "101637  CREATE TABLE table_78359 (\\n    \"Year\" real,\\n...   \n",
       "\n",
       "                                                 response              source  \\\n",
       "89664   SELECT \"origin\" FROM table_204_710 GROUP BY \"o...              squall   \n",
       "166686  SELECT T1.Name, T1.Manufacturer FROM Products ...             nvbench   \n",
       "243193  SELECT result FROM table_name_76 WHERE couple ...  sql_create_context   \n",
       "254344  SELECT publisher FROM book_club EXCEPT SELECT ...              spider   \n",
       "101637  SELECT \"Ratings\" FROM table_78359 WHERE \"Year\"...             wikisql   \n",
       "\n",
       "                                                     text  \n",
       "89664   Below are sql tables schemas paired with instr...  \n",
       "166686  Below are sql tables schemas paired with instr...  \n",
       "243193  Below are sql tables schemas paired with instr...  \n",
       "254344  Below are sql tables schemas paired with instr...  \n",
       "101637  Below are sql tables schemas paired with instr...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"Clinton/Text-to-SQL-v1\")\n",
    "shuffled_dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "df = pd.DataFrame(shuffled_dataset[\"train\"])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size: 262206\n"
     ]
    }
   ],
   "source": [
    "df_clean = df[df[\"instruction\"] != \"\"].reset_index(drop=True)\n",
    "print(f\"Filtered dataset size: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 235985\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 26221\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "formatted_dataset = Dataset.from_pandas(df_clean[[\"text\"]])\n",
    "formatted_dataset = formatted_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "print(formatted_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smart Padding\n",
    "def tokenize(examples):\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    max_length = 4096\n",
    "\n",
    "    for full_text in examples[\"text\"]:\n",
    "        # Extract prompt and response\n",
    "        prompt_text = full_text.split(\"### Response:\")[0].strip() + \"\\n### Response:\\n\"\n",
    "        response_text = full_text.split(\"### Response:\")[1].strip()\n",
    "        \n",
    "        # Tokenize with truncation\n",
    "        prompt_tokens = tokenizer(prompt_text, truncation=True, max_length=max_length)[\"input_ids\"]\n",
    "        response_tokens = tokenizer(response_text, truncation=True, max_length=max_length)[\"input_ids\"]\n",
    "        response_tokens.append(tokenizer.eos_token_id)\n",
    "        \n",
    "        # Combine tokens for input\n",
    "        input_ids = prompt_tokens + response_tokens\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        \n",
    "        # Create labels - keep prompt tokens, mask response tokens\n",
    "        labels = input_ids.copy()  # Start with full sequence\n",
    "        labels = [-100] * len(prompt_tokens) + response_tokens #mask prompt tokens\n",
    "\n",
    "        input_ids_list.append(input_ids)\n",
    "        attention_mask_list.append(attention_mask)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids_list,\n",
    "        \"attention_mask\": attention_mask_list,\n",
    "        \"labels\": labels_list\n",
    "    }\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # because this is causal LM\n",
    "    pad_to_multiple_of=16  # speeds up training on GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import re\n",
    "\n",
    "def fix_missing_semicolons(sql_code):\n",
    "    \"\"\"\n",
    "    Inserts semicolons between multiple CREATE TABLE statements if missing.\n",
    "    Looks for patterns like `) CREATE TABLE` and adds a semicolon between them.\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\)\\s*(?=CREATE TABLE)', r');\\n', sql_code.strip())\n",
    "\n",
    "def can_execute_sql(generated_sql, schema=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Check if a SQL query or script can be executed against a given schema.\n",
    "\n",
    "    Args:\n",
    "        generated_sql (str): The SQL query or script to test.\n",
    "        schema (str, optional): The database schema to create before testing.\n",
    "        verbose (bool, optional): Whether to print detailed errors.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (bool, str) - (success status, message or error)\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(\":memory:\")\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Create schema if provided\n",
    "        if schema:\n",
    "            try:\n",
    "                schema = fix_missing_semicolons(schema)\n",
    "                cursor.executescript(schema)\n",
    "                conn.commit()\n",
    "            except sqlite3.Error as e:\n",
    "                if verbose:\n",
    "                    print(\"Schema execution failed.\")\n",
    "                    print(\"Error:\", e)\n",
    "                return False\n",
    "\n",
    "        # Execute the query or script\n",
    "        try:\n",
    "            if ';' in generated_sql.strip().rstrip(';'):\n",
    "                cursor.executescript(generated_sql)\n",
    "                return True\n",
    "            else:\n",
    "                cursor.execute(generated_sql)\n",
    "                return True\n",
    "        except sqlite3.Error as e:\n",
    "            if verbose:\n",
    "                print(\"Query execution failed.\")\n",
    "                print(\"Error:\", e)\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(\"General error.\")\n",
    "            print(\"Error:\", e)\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#computing the metrics for the baseline model based on similarilty of output, sql compilation and time\n",
    "\n",
    "# Load metrics\n",
    "meteor_metric = evaluate.load(\"meteor\")\n",
    "\n",
    "def extract_sql_from_output(output_text, prompt_text):\n",
    "    \"\"\"Extract SQL query from model output, handling various formats.\"\"\"\n",
    "    # Remove the prompt from the output\n",
    "    sql_text = output_text[len(prompt_text):].strip()\n",
    "    \n",
    "    # Remove any markdown code blocks if present\n",
    "    sql_text = re.sub(r'```sql\\s*|\\s*```', '', sql_text)\n",
    "    sql_text = re.sub(r'```\\s*|\\s*```', '', sql_text)\n",
    "    \n",
    "    # Remove any trailing text after semicolon\n",
    "    if ';' in sql_text:\n",
    "        sql_text = sql_text.split(';')[0] + ';'\n",
    "    \n",
    "    return sql_text.strip()\n",
    "\n",
    "def evaluate_model_on_dataset(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    dataset,\n",
    "    max_new_tokens=248\n",
    "):\n",
    "    predictions = []\n",
    "    references = []\n",
    "    compile_success = 0\n",
    "    execution_times = []\n",
    "\n",
    "    dataset_slice = dataset\n",
    "\n",
    "    for example in tqdm(dataset_slice, desc=\"Evaluating\"):\n",
    "        # Extract prompt and response using the same format as tokenize function\n",
    "        prompt_text = example[\"text\"].split(\"### Response:\")[0].strip() + \"\\n### Response:\\n\"\n",
    "        ground_truth = example[\"text\"].split(\"### Response:\")[1].strip()\n",
    "        schema = example[\"text\"].split(\"### Input:\")[1].split(\"### Response:\")[0].strip()\n",
    "\n",
    "        inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.95,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                max_new_tokens=max_new_tokens\n",
    "                )\n",
    "        \n",
    "        # Get the generated SQL - everything after the prompt\n",
    "        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        #generated_sql = extract_sql_from_output(decoded, prompt_text)\n",
    "        generated_sql = decoded.split(\"### Response:\")[-1].strip().split(\"###\")[0]\n",
    "        print(\"SQL Output:\", generated_sql)\n",
    "\n",
    "        # Add prediction for METEOR\n",
    "        predictions.append(generated_sql)\n",
    "        references.append([ground_truth])  # METEOR expects references as a list of lists\n",
    "\n",
    "        # Compile SQL Query and measure time\n",
    "        start_time = time.perf_counter()\n",
    "        success = can_execute_sql(generated_sql, schema)\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        if success:\n",
    "            compile_success += 1\n",
    "            execution_times.append(end_time - start_time)\n",
    "\n",
    "    # Compute metrics\n",
    "    meteor_score = meteor_metric.compute(predictions=predictions, references=references)[\"meteor\"]\n",
    "    sql_compilation_rate = compile_success / len(dataset_slice)\n",
    "    \n",
    "    # Calculate average execution time for successful queries\n",
    "    avg_execution_time = sum(execution_times) / len(execution_times) if execution_times else 0\n",
    "\n",
    "    metrics = {\n",
    "        \"meteor_score\": round(meteor_score, 4),\n",
    "        \"sql_compilation_rate\": round(sql_compilation_rate, 4),\n",
    "        \"avg_execution_time_ms\": round(avg_execution_time * 1000, 2),  # Convert to milliseconds\n",
    "        \"num_eval_samples\": len(dataset_slice),\n",
    "        \"num_successful_queries\": compile_success\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32256, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=2048, out_features=5504, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=2048, out_features=5504, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=5504, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=32256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the finetuned model from checkpoint 3750 in the correct directory\n",
    "model_finetune = PeftModel.from_pretrained(\n",
    "    base_model, \n",
    "    \"./deepseek-coder-qlora-sql/checkpoint-3750\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model_finetune.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\t\n",
    "Below are sql tables schemas paired with instruction that describes a task. Using valid SQLite, write a response that appropriately completes the request for the provided tables. ### Instruction: What model has a launch of September 3, 2010? ### Input: CREATE TABLE table_28269 (\n",
    "\"Model\" text,\n",
    "\"Launch\" text,\n",
    "\"Code name\" text,\n",
    "\"Transistors (million)\" real,\n",
    "\"Die size (mm 2 )\" real,\n",
    "\"Bus interface\" text,\n",
    "\"Memory ( MB )\" text,\n",
    "\"SM count\" real,\n",
    "\"Core config 1,3\" text,\n",
    "\"Core ( MHz )\" real,\n",
    "\"Shader ( MHz )\" real,\n",
    "\"Memory ( MHz )\" text,\n",
    "\"Pixel ( GP /s)\" text,\n",
    "\"Texture ( GT /s)\" text,\n",
    "\"Bandwidth ( GB /s)\" text,\n",
    "\"DRAM type\" text,\n",
    "\"Bus width ( bit )\" real,\n",
    "\"GFLOPS (FMA) 2\" text,\n",
    "\"TDP (watts)\" real,\n",
    "\"Release price (USD)\" text\n",
    ") ### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \"Model\" FROM table_28269 WHERE \"Launch\" = 'September 3, 2010' ORDER BY \"Model\" LIMIT 1\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model_finetune.generate(\n",
    "                **inputs,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                max_new_tokens=2048,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "\n",
    "generated_sql = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# Extract only the response part (everything after \"### Response:\")\n",
    "generated_sql = generated_sql.split(\"### Response:\")[-1].strip().split(\"###\")[0]\n",
    "print(generated_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fine-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  10%|█         | 1/10 [00:01<00:14,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT high_points FROM table_13464416_4 WHERE game = \"7\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  20%|██        | 2/10 [00:17<01:22, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT COUNT(\"Player\") FROM table_1007 WHERE \"Prior experience\" = 'shasta h.s.' AND \"Class\" = 'Class' \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  30%|███       | 3/10 [00:34<01:31, 13.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT MIN(admissions.dischtime) FROM admissions INNER JOIN patients ON admissions.subject_id = patients.subject_id WHERE patients.gender = 'female' AND patients.dob BETWEEN '2104-01-01' AND '2104-12-31' AND admissions.dischtime BETWEEN '2104-01-01' AND '2104-12-31' AND admissions.admission_type = 'ICULAB' AND admissions.discharge_location = 'Hospital' AND patients.gender = 'female' AND patients.dob BETWEEN '2104-01-01' AND '2104-12-31' AND admissions.dischtime BETWEEN '2104-01-01' AND '2104-12-31' AND admissions.admission_type = 'ICULAB' AND admissions.discharge_location = 'Hospital' AND patients.gender = 'female' AND\n",
      "Query execution failed.\n",
      "Error: incomplete input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  40%|████      | 4/10 [00:50<01:25, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT \"Height in Ft.\" FROM table_10263 WHERE \"Player\" = 'ILiillinois' \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  50%|█████     | 5/10 [01:06<01:14, 14.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT \"Military expenditures (2011, % of GDP)\" FROM table_1788 WHERE \"Country\" = 'Romania' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Population (2011)\" = '725,1167' AND \"GDP (nominal) (2010, US$ millions)\" = '8205,3578' AND \"Military expenditures (2011, US$ millions)\" = '772,2374' AND \"Defence expenditures, (2011, per capita)\" = '34,632,092' AND \"Deployable military (2011, thousands)\" = '6,415,330' AND \"Country\" = 'Romania' AND \"Population (2011)\" = '725,1167' AND \"GDP (nominal) (2010, US$ millions)\" = '8205,3578\n",
      "Query execution failed.\n",
      "Error: unrecognized token: \"'8205,3578\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  60%|██████    | 6/10 [01:22<01:01, 15.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT food_service.meal_description FROM food_service INNER JOIN (SELECT MAX(flight.flight_id) AS flight_id FROM flight WHERE flight.from_airport = 'PHILADELPHIA' AND flight.to_airport = 'ATLANTA' AND flight.departure_time < '2400' AND flight.arrival_time > '2400') AS flight ON food_service.meal_number = flight.flight_id INNER JOIN (SELECT MAX(flight.flight_id) AS flight_id FROM flight WHERE flight.from_airport = 'PHILADELPHIA' AND flight.to_airport = 'ATLANTA' AND flight.departure_time < '2400' AND flight.arrival_time > '2400' AND flight.stops = 1) AS flight_stop ON food_service.meal_number = flight_stop.flight_id WHERE food_service.meal_number = flight_stop.flight_id INNER JOIN (SELECT MAX(flight.flight\n",
      "Query execution failed.\n",
      "Error: near \"INNER\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  70%|███████   | 7/10 [01:27<00:35, 11.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT \"Label\" FROM table_8208 WHERE \"Date\" = '1985' AND \"Label\" = 'original cd' AND \"Region\" = 'united states' AND \"Format\" = 'cd' AND \"Version\" = 'cd 2' AND \"Label\" = 'original cd'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  80%|████████  | 8/10 [01:42<00:25, 12.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT \"Youth Classification\" FROM table_26425 WHERE \"General classification\" = 'michael barry' AND \"Stage (Winner)\" = '12' AND \"Mountains Classification\" = '6' AND \"Aggressive Rider\" = '13' AND \"Team Classification\" = '13' AND \"Sprint Classification\" = '2' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = '2' AND \"Mountains Classification\" = '6' AND \"Youth Classification\" = '2' AND \"Aggressive Rider\" = '13' AND \"Stage (Winner)\" = '12' AND \"General classification\" = 'michael barry' AND \"Team Classification\" = '13' AND \"Sprint Classification\" = '2' AND \"General classification\" = 'michael barry' AND \"Youth Classification\" = '2' AND \"Stage (Winner)\" = '12' AND \"Sprint Classification\" = '2' AND \"Aggressive Rider\" = '13' AND\n",
      "Query execution failed.\n",
      "Error: incomplete input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  90%|█████████ | 9/10 [01:44<00:09,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT COUNT(Country) AS \"Total Number\", Country AS \"Rank\" FROM airport GROUP BY Country ORDER BY \"Total Number\" DESC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [02:00<00:00, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT record FROM table_22669044_8 WHERE location_attendance = \"united center 18,838\" \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuned Model Performance:\n",
      "Metric                    Value          \n",
      "----------------------------------------\n",
      "meteor_score              0.6510         \n",
      "sql_compilation_rate      0.6000         \n",
      "avg_execution_time_ms     0.3800         \n",
      "\n",
      "Number of samples evaluated: 10\n",
      "Number of successful queries: 6\n"
     ]
    }
   ],
   "source": [
    "# Evaluate fine-tuned model performance\n",
    "print(\"Evaluating fine-tuned model...\")\n",
    "\n",
    "# Create a test set\n",
    "test_samples = formatted_dataset[\"test\"].select(range(10))  # Using 10 samples for evaluation\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "finetuned_metrics = evaluate_model_on_dataset(\n",
    "    model=model_finetune,  # Fine-tuned model\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=test_samples,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nFine-tuned Model Performance:\")\n",
    "print(f\"{'Metric':<25} {'Value':<15}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for metric in ['meteor_score', 'sql_compilation_rate', 'avg_execution_time_ms']:\n",
    "    value = finetuned_metrics[metric]\n",
    "    print(f\"{metric:<25} {value:<15.4f}\")\n",
    "\n",
    "print(f\"\\nNumber of samples evaluated: {finetuned_metrics['num_eval_samples']}\")\n",
    "print(f\"Number of successful queries: {finetuned_metrics['num_successful_queries']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepseek-finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
