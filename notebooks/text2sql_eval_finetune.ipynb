{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Core Libraries ---\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# --- Hugging Face: Dataset, Tokenizer, Model ---\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    TrainingArguments, \n",
    "    Trainer, \n",
    "    DataCollatorForLanguageModeling,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "# --- LoRA & Parameter-Efficient Tuning ---\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "\n",
    "# --- W&B Experiment Tracking ---\n",
    "import wandb\n",
    "\n",
    "# --- SQL Evaluation ---\n",
    "import sqlite3\n",
    "import sqlparse\n",
    "from tabulate import tabulate\n",
    "import evaluate  # for BLEU, ROUGE\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "Using GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"GPU not detected — will fall back to CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>response</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>What is the location and total attendance for ...</td>\n",
       "      <td>CREATE TABLE table_15872814_5 (\\n    location_...</td>\n",
       "      <td>SELECT location_attendance FROM table_15872814...</td>\n",
       "      <td>sql_create_context</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166650</th>\n",
       "      <td>A bar chart for finding the number of the part...</td>\n",
       "      <td>CREATE TABLE election (\\n    Election_ID int,\\...</td>\n",
       "      <td>SELECT Governor, COUNT(Governor) FROM election...</td>\n",
       "      <td>nvbench</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160253</th>\n",
       "      <td>How many documents have expenses?</td>\n",
       "      <td>CREATE TABLE ref_budget_codes (\\n    budget_ty...</td>\n",
       "      <td>SELECT COUNT(*) FROM documents_with_expenses</td>\n",
       "      <td>spider</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25504</th>\n",
       "      <td>For those employees who was hired before 2002-...</td>\n",
       "      <td>CREATE TABLE departments (\\n    DEPARTMENT_ID ...</td>\n",
       "      <td>SELECT JOB_ID, AVG(MANAGER_ID) FROM employees ...</td>\n",
       "      <td>nvbench</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21890</th>\n",
       "      <td>List the names of technicians in ascending ord...</td>\n",
       "      <td>CREATE TABLE technician (\\n    Name VARCHAR,\\n...</td>\n",
       "      <td>SELECT Name FROM technician ORDER BY Age</td>\n",
       "      <td>sql_create_context</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              instruction  \\\n",
       "39769   What is the location and total attendance for ...   \n",
       "166650  A bar chart for finding the number of the part...   \n",
       "160253                  How many documents have expenses?   \n",
       "25504   For those employees who was hired before 2002-...   \n",
       "21890   List the names of technicians in ascending ord...   \n",
       "\n",
       "                                                    input  \\\n",
       "39769   CREATE TABLE table_15872814_5 (\\n    location_...   \n",
       "166650  CREATE TABLE election (\\n    Election_ID int,\\...   \n",
       "160253  CREATE TABLE ref_budget_codes (\\n    budget_ty...   \n",
       "25504   CREATE TABLE departments (\\n    DEPARTMENT_ID ...   \n",
       "21890   CREATE TABLE technician (\\n    Name VARCHAR,\\n...   \n",
       "\n",
       "                                                 response              source  \\\n",
       "39769   SELECT location_attendance FROM table_15872814...  sql_create_context   \n",
       "166650  SELECT Governor, COUNT(Governor) FROM election...             nvbench   \n",
       "160253       SELECT COUNT(*) FROM documents_with_expenses              spider   \n",
       "25504   SELECT JOB_ID, AVG(MANAGER_ID) FROM employees ...             nvbench   \n",
       "21890            SELECT Name FROM technician ORDER BY Age  sql_create_context   \n",
       "\n",
       "                                                     text  \n",
       "39769   Below are sql tables schemas paired with instr...  \n",
       "166650  Below are sql tables schemas paired with instr...  \n",
       "160253  Below are sql tables schemas paired with instr...  \n",
       "25504   Below are sql tables schemas paired with instr...  \n",
       "21890   Below are sql tables schemas paired with instr...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"Clinton/Text-to-SQL-v1\")\n",
    "shuffled_dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "df = pd.DataFrame(shuffled_dataset[\"train\"])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size: 262206\n"
     ]
    }
   ],
   "source": [
    "df_clean = df[df[\"instruction\"] != \"\"].reset_index(drop=True)\n",
    "print(f\"Filtered dataset size: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 235985\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 26221\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "formatted_dataset = Dataset.from_pandas(df_clean[[\"text\"]])\n",
    "formatted_dataset = formatted_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "print(formatted_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smart Padding\n",
    "def tokenize(examples):\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    max_length = 4096\n",
    "\n",
    "    for full_text in examples[\"text\"]:\n",
    "        # Extract prompt and response\n",
    "        prompt_text = full_text.split(\"### Response:\")[0].strip() + \"\\n### Response:\\n\"\n",
    "        response_text = full_text.split(\"### Response:\")[1].strip()\n",
    "        \n",
    "        # Tokenize with truncation\n",
    "        prompt_tokens = tokenizer(prompt_text, truncation=True, max_length=max_length)[\"input_ids\"]\n",
    "        response_tokens = tokenizer(response_text, truncation=True, max_length=max_length)[\"input_ids\"]\n",
    "        response_tokens.append(tokenizer.eos_token_id)\n",
    "        \n",
    "        # Combine tokens for input\n",
    "        input_ids = prompt_tokens + response_tokens\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        \n",
    "        # Create labels - keep prompt tokens, mask response tokens\n",
    "        labels = input_ids.copy()  # Start with full sequence\n",
    "        labels = [-100] * len(prompt_tokens) + response_tokens #mask prompt tokens\n",
    "\n",
    "        input_ids_list.append(input_ids)\n",
    "        attention_mask_list.append(attention_mask)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids_list,\n",
    "        \"attention_mask\": attention_mask_list,\n",
    "        \"labels\": labels_list\n",
    "    }\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # because this is causal LM\n",
    "    pad_to_multiple_of=16  # speeds up training on GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import re\n",
    "\n",
    "def fix_missing_semicolons(sql_code):\n",
    "    \"\"\"\n",
    "    Inserts semicolons between multiple CREATE TABLE statements if missing.\n",
    "    Looks for patterns like `) CREATE TABLE` and adds a semicolon between them.\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\)\\s*(?=CREATE TABLE)', r');\\n', sql_code.strip())\n",
    "\n",
    "def can_execute_sql(generated_sql, schema=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Check if a SQL query or script can be executed against a given schema.\n",
    "\n",
    "    Args:\n",
    "        generated_sql (str): The SQL query or script to test.\n",
    "        schema (str, optional): The database schema to create before testing.\n",
    "        verbose (bool, optional): Whether to print detailed errors.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (bool, str) - (success status, message or error)\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(\":memory:\")\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Create schema if provided\n",
    "        if schema:\n",
    "            try:\n",
    "                schema = fix_missing_semicolons(schema)\n",
    "                cursor.executescript(schema)\n",
    "                conn.commit()\n",
    "            except sqlite3.Error as e:\n",
    "                if verbose:\n",
    "                    print(\"Schema execution failed.\")\n",
    "                    print(\"Error:\", e)\n",
    "                return False\n",
    "\n",
    "        # Execute the query or script\n",
    "        try:\n",
    "            if ';' in generated_sql.strip().rstrip(';'):\n",
    "                cursor.executescript(generated_sql)\n",
    "                return True\n",
    "            else:\n",
    "                cursor.execute(generated_sql)\n",
    "                return True\n",
    "        except sqlite3.Error as e:\n",
    "            if verbose:\n",
    "                print(\"Query execution failed.\")\n",
    "                print(\"Error:\", e)\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(\"General error.\")\n",
    "            print(\"Error:\", e)\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#computing the metrics for the baseline model based on similarilty of output, sql compilation and time\n",
    "\n",
    "# Load metrics\n",
    "meteor_metric = evaluate.load(\"meteor\")\n",
    "\n",
    "def extract_sql_from_output(output_text, prompt_text):\n",
    "    \"\"\"Extract SQL query from model output, handling various formats.\"\"\"\n",
    "    # Remove the prompt from the output\n",
    "    sql_text = output_text[len(prompt_text):].strip()\n",
    "    \n",
    "    # Remove any markdown code blocks if present\n",
    "    sql_text = re.sub(r'```sql\\s*|\\s*```', '', sql_text)\n",
    "    sql_text = re.sub(r'```\\s*|\\s*```', '', sql_text)\n",
    "    \n",
    "    # Remove any trailing text after semicolon\n",
    "    if ';' in sql_text:\n",
    "        sql_text = sql_text.split(';')[0] + ';'\n",
    "    \n",
    "    return sql_text.strip()\n",
    "\n",
    "def evaluate_model_on_dataset(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    dataset,\n",
    "    max_new_tokens=2048\n",
    "):\n",
    "    predictions = []\n",
    "    references = []\n",
    "    compile_success = 0\n",
    "    execution_times = []\n",
    "\n",
    "    dataset_slice = dataset\n",
    "\n",
    "    for example in tqdm(dataset_slice, desc=\"Evaluating\"):\n",
    "        # Extract prompt and response using the same format as tokenize function\n",
    "        prompt_text = example[\"text\"].split(\"### Response:\")[0].strip() + \"\\n### Response:\\n\"\n",
    "        ground_truth = example[\"text\"].split(\"### Response:\")[1].strip()\n",
    "        schema = example[\"text\"].split(\"### Input:\")[1].split(\"### Response:\")[0].strip()\n",
    "\n",
    "        inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                max_new_tokens=2048,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "        \n",
    "        # Get the generated SQL - everything after the prompt\n",
    "        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        #generated_sql = extract_sql_from_output(decoded, prompt_text)\n",
    "        generated_sql = decoded.split(\"### Response:\")[-1].strip().split(\"###\")[0]\n",
    "        print(\"SQL Output:\", generated_sql)\n",
    "\n",
    "        # Add prediction for METEOR\n",
    "        predictions.append(generated_sql)\n",
    "        references.append([ground_truth])  # METEOR expects references as a list of lists\n",
    "\n",
    "        # Compile SQL Query and measure time\n",
    "        start_time = time.perf_counter()\n",
    "        success = can_execute_sql(generated_sql, schema)\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        if success:\n",
    "            compile_success += 1\n",
    "            execution_times.append(end_time - start_time)\n",
    "\n",
    "    # Compute metrics\n",
    "    meteor_score = meteor_metric.compute(predictions=predictions, references=references)[\"meteor\"]\n",
    "    sql_compilation_rate = compile_success / len(dataset_slice)\n",
    "    \n",
    "    # Calculate average execution time for successful queries\n",
    "    avg_execution_time = sum(execution_times) / len(execution_times) if execution_times else 0\n",
    "\n",
    "    metrics = {\n",
    "        \"meteor_score\": round(meteor_score, 4),\n",
    "        \"sql_compilation_rate\": round(sql_compilation_rate, 4),\n",
    "        \"avg_execution_time_ms\": round(avg_execution_time * 1000, 2),  # Convert to milliseconds\n",
    "        \"num_eval_samples\": len(dataset_slice),\n",
    "        \"num_successful_queries\": compile_success\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32256, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=2048, out_features=5504, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=2048, out_features=5504, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=5504, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=32256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the finetuned model from checkpoint 3750 in the correct directory\n",
    "model_finetune = PeftModel.from_pretrained(\n",
    "    base_model, \n",
    "    \"./deepseek-coder-qlora-sql/checkpoint-3750\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model_finetune.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\t\n",
    "Below are sql tables schemas paired with instruction that describes a task. Using valid SQLite, write a response that appropriately completes the request for the provided tables. ### Instruction: What model has a launch of September 3, 2010? ### Input: CREATE TABLE table_28269 (\n",
    "\"Model\" text,\n",
    "\"Launch\" text,\n",
    "\"Code name\" text,\n",
    "\"Transistors (million)\" real,\n",
    "\"Die size (mm 2 )\" real,\n",
    "\"Bus interface\" text,\n",
    "\"Memory ( MB )\" text,\n",
    "\"SM count\" real,\n",
    "\"Core config 1,3\" text,\n",
    "\"Core ( MHz )\" real,\n",
    "\"Shader ( MHz )\" real,\n",
    "\"Memory ( MHz )\" text,\n",
    "\"Pixel ( GP /s)\" text,\n",
    "\"Texture ( GT /s)\" text,\n",
    "\"Bandwidth ( GB /s)\" text,\n",
    "\"DRAM type\" text,\n",
    "\"Bus width ( bit )\" real,\n",
    "\"GFLOPS (FMA) 2\" text,\n",
    "\"TDP (watts)\" real,\n",
    "\"Release price (USD)\" text\n",
    ") ### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \"Model\" FROM table_28269 WHERE \"Launch\" = 'September 3, 2010' ORDER BY \"Model\" LIMIT 1\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model_finetune.generate(\n",
    "                **inputs,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                max_new_tokens=2048,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "\n",
    "generated_sql = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# Extract only the response part (everything after \"### Response:\")\n",
    "generated_sql = generated_sql.split(\"### Response:\")[-1].strip().split(\"###\")[0]\n",
    "print(generated_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fine-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  10%|█         | 1/10 [02:24<21:43, 144.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT high_points FROM table_13464416_4 WHERE game = \"7\" ORDER BY DESC LIMIT 10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "Query execution failed.\n",
      "Error: no such column: DESC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  20%|██        | 2/10 [04:39<18:31, 138.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT COUNT(\"Player\") FROM table_1007 WHERE \"Prior experience\" = 'shasta h.s.' AND \"Class\" = 'class' \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  30%|███       | 3/10 [07:41<18:30, 158.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT MIN(charttime) FROM chartevents WHERE subject_id = 48706 AND itemid = 10000000 AND charttime > '2104' AND icustay_id IS NULL AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706) AND icustay_id IN (SELECT icustay_id FROM icustays WHERE subject_id = 48706) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '10000000' AND hadm_id IN (SELECT hadm_id FROM admissions WHERE subject_id = 48706)) AND icustay_id IN (SELECT icustay_id FROM diagnoses_icd WHERE subject_id = 48706 AND icd9_code = '1000000\n",
      "Query execution failed.\n",
      "Error: unrecognized token: \"'1000000\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  40%|████      | 4/10 [10:26<16:06, 161.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT \"Height in Ft.\" FROM table_10263 WHERE \"Player\" = 'illinois' \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  50%|█████     | 5/10 [12:37<12:30, 150.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT \"Military expenditures (2011, % of GDP)\" FROM table_1788 WHERE \"Country\" = 'romania' AND \"Population (2011)\" = '2011' AND \"GDP (nominal) (2010, US$ millions)\" = '2011' AND \"Military expenditures (2011, US$ millions)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Defence expenditures, (2011, per capita)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Country\" = 'romania' AND \"Population (2011)\" = '2011' AND \"GDP (nominal) (2010, US$ millions)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Defence expenditures, (2011, per capita)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, US$ millions)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Defence expenditures, (2011, per capita)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"GDP (nominal) (2010, US$ millions)\" = '2011' AND \"Military expenditures (2011, US$ millions)\" = '2011' AND \"Defence expenditures, (2011, per capita)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military expenditures (2011, % of GDP)\" = '2011' AND \"Deployable military (2011, thousands)\" = '2011' AND \"Military\n",
      "Query execution failed.\n",
      "Error: unrecognized token: \"\"Military\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  60%|██████    | 6/10 [14:41<09:25, 141.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT DISTINCT flight.flight_id FROM flight JOIN city ON city.city_code = flight.from_airport JOIN airport ON airport.airport_code = city.state_code JOIN airport ON airport.airport_code = flight.to_airport WHERE flight.airline_code = 'PHILADELPHIA' AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.arrival_time > 1000000 AND flight.departure_time < 1000000 AND flight.\n",
      "Query execution failed.\n",
      "Error: incomplete input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  70%|███████   | 7/10 [16:47<06:48, 136.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT \"Label\" FROM table_8208 WHERE \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\" = '1.00' AND \"Label\" = 'Original CD' AND \"Date\" = '1995-01-01' AND \"Region\" = 'USA' AND \"Format\" = 'CD' AND \"Version\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  80%|████████  | 8/10 [19:03<04:32, 136.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT \"Youth Classification\" FROM table_26425 WHERE \"Aggressive Rider\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Team Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"Stage (Winner)\" = 'michael barry' AND \"General classification\" = 'michael barry' AND \"Sprint Classification\" = 'michael barry' AND \"Mountains Classification\" = 'michael barry' AND \"Youth Classification\" = 'michael barry' AND \"\n",
      "Query execution failed.\n",
      "Error: unrecognized token: \"\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  90%|█████████ | 9/10 [21:22<02:17, 137.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT COUNT(*) AS \"\n",
      "Query execution failed.\n",
      "Error: unrecognized token: \"\"\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [23:35<00:00, 141.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Output: SELECT record FROM table_22669044_8 WHERE location_attendance =\n",
      "Query execution failed.\n",
      "Error: incomplete input\n",
      "\n",
      "Fine-tuned Model Performance:\n",
      "Metric                    Value          \n",
      "----------------------------------------\n",
      "meteor_score              0.4016         \n",
      "sql_compilation_rate      0.3000         \n",
      "avg_execution_time_ms     0.6100         \n",
      "\n",
      "Number of samples evaluated: 10\n",
      "Number of successful queries: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate fine-tuned model performance\n",
    "print(\"Evaluating fine-tuned model...\")\n",
    "\n",
    "# Create a test set\n",
    "test_samples = formatted_dataset[\"test\"].select(range(10))  # Using 10 samples for evaluation\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "finetuned_metrics = evaluate_model_on_dataset(\n",
    "    model=model_finetune,  # Fine-tuned model\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=test_samples,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nFine-tuned Model Performance:\")\n",
    "print(f\"{'Metric':<25} {'Value':<15}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for metric in ['meteor_score', 'sql_compilation_rate', 'avg_execution_time_ms']:\n",
    "    value = finetuned_metrics[metric]\n",
    "    print(f\"{metric:<25} {value:<15.4f}\")\n",
    "\n",
    "print(f\"\\nNumber of samples evaluated: {finetuned_metrics['num_eval_samples']}\")\n",
    "print(f\"Number of successful queries: {finetuned_metrics['num_successful_queries']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepseek-finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
