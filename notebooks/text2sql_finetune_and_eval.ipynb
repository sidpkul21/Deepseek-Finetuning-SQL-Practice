{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29de831d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Core Libraries ---\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# --- Hugging Face: Dataset, Tokenizer, Model ---\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    TrainingArguments, \n",
    "    Trainer, \n",
    "    DataCollatorForLanguageModeling,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "# --- LoRA & Parameter-Efficient Tuning ---\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# --- W&B Experiment Tracking ---\n",
    "import wandb\n",
    "\n",
    "# --- SQL Evaluation ---\n",
    "import sqlite3\n",
    "import sqlparse\n",
    "from tabulate import tabulate\n",
    "import evaluate  # for BLEU, ROUGE\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f6810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"text2sql_finetune_and_eval.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f182440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "Using GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"GPU not detected â€” will fall back to CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9fc0eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>response</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172776</th>\n",
       "      <td>What rowers have a 6:29.56 time?</td>\n",
       "      <td>CREATE TABLE table_62947 (\\n    \"Rank\" real,\\n...</td>\n",
       "      <td>SELECT \"Rowers\" FROM table_62947 WHERE \"Time\" ...</td>\n",
       "      <td>wikisql</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55857</th>\n",
       "      <td>What is the average capacity for the vehicle h...</td>\n",
       "      <td>CREATE TABLE table_65050 (\\n    \"Driver\" text,...</td>\n",
       "      <td>SELECT AVG(\"Capacity\") FROM table_65050 WHERE ...</td>\n",
       "      <td>wikisql</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107337</th>\n",
       "      <td>Find the names of nurses who are on call.</td>\n",
       "      <td>CREATE TABLE medication (\\n    code number,\\n ...</td>\n",
       "      <td>SELECT DISTINCT T1.name FROM nurse AS T1 JOIN ...</td>\n",
       "      <td>spider</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230584</th>\n",
       "      <td>What title was used in the nomination of the S...</td>\n",
       "      <td>CREATE TABLE table_65600 (\\n    \"Year (Ceremon...</td>\n",
       "      <td>SELECT \"Film title used in nomination\" FROM ta...</td>\n",
       "      <td>wikisql</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171681</th>\n",
       "      <td>List the types of competition and the number o...</td>\n",
       "      <td>CREATE TABLE club (\\n    Club_ID int,\\n    nam...</td>\n",
       "      <td>SELECT Competition_type, COUNT(*) FROM competi...</td>\n",
       "      <td>nvbench</td>\n",
       "      <td>Below are sql tables schemas paired with instr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              instruction  \\\n",
       "172776                   What rowers have a 6:29.56 time?   \n",
       "55857   What is the average capacity for the vehicle h...   \n",
       "107337          Find the names of nurses who are on call.   \n",
       "230584  What title was used in the nomination of the S...   \n",
       "171681  List the types of competition and the number o...   \n",
       "\n",
       "                                                    input  \\\n",
       "172776  CREATE TABLE table_62947 (\\n    \"Rank\" real,\\n...   \n",
       "55857   CREATE TABLE table_65050 (\\n    \"Driver\" text,...   \n",
       "107337  CREATE TABLE medication (\\n    code number,\\n ...   \n",
       "230584  CREATE TABLE table_65600 (\\n    \"Year (Ceremon...   \n",
       "171681  CREATE TABLE club (\\n    Club_ID int,\\n    nam...   \n",
       "\n",
       "                                                 response   source  \\\n",
       "172776  SELECT \"Rowers\" FROM table_62947 WHERE \"Time\" ...  wikisql   \n",
       "55857   SELECT AVG(\"Capacity\") FROM table_65050 WHERE ...  wikisql   \n",
       "107337  SELECT DISTINCT T1.name FROM nurse AS T1 JOIN ...   spider   \n",
       "230584  SELECT \"Film title used in nomination\" FROM ta...  wikisql   \n",
       "171681  SELECT Competition_type, COUNT(*) FROM competi...  nvbench   \n",
       "\n",
       "                                                     text  \n",
       "172776  Below are sql tables schemas paired with instr...  \n",
       "55857   Below are sql tables schemas paired with instr...  \n",
       "107337  Below are sql tables schemas paired with instr...  \n",
       "230584  Below are sql tables schemas paired with instr...  \n",
       "171681  Below are sql tables schemas paired with instr...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"Clinton/Text-to-SQL-v1\")\n",
    "shuffled_dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "df = pd.DataFrame(shuffled_dataset[\"train\"])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c0edcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any nulls? instruction    0\n",
      "input          0\n",
      "response       0\n",
      "source         0\n",
      "text           0\n",
      "dtype: int64\n",
      "Any empty strings? instruction    2\n",
      "input          0\n",
      "response       0\n",
      "source         0\n",
      "text           0\n",
      "dtype: int64\n",
      "Unique columns: Index(['instruction', 'input', 'response', 'source', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Any nulls?\", df.isna().sum())\n",
    "print(\"Any empty strings?\", (df == \"\").sum())\n",
    "print(\"Unique columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c82272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size: 262206\n"
     ]
    }
   ],
   "source": [
    "df_clean = df[df[\"instruction\"] != \"\"].reset_index(drop=True)\n",
    "print(f\"Filtered dataset size: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "919d9e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 235985\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 26221\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "formatted_dataset = Dataset.from_pandas(df_clean[[\"text\"]])\n",
    "formatted_dataset = formatted_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "print(formatted_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "245b4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e64955d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Token Length Stats: {'max': 3226, '95th_percentile': 1435, 'mean': np.float64(377.15), 'min': 66, 'num_samples': 235985}\n",
      "Test Token Length Stats: {'max': 3218, '95th_percentile': 1420, 'mean': np.float64(376.35), 'min': 69, 'num_samples': 26221}\n"
     ]
    }
   ],
   "source": [
    "# Find max length of instructions to pick the optimal max prompt length\n",
    "\n",
    "# Function to compute token length stats\n",
    "def compute_token_stats(dataset_split, tokenizer):\n",
    "    lengths = [len(tokenizer(x)[\"input_ids\"]) for x in dataset_split[\"text\"]]\n",
    "    stats = {\n",
    "        \"max\": int(np.max(lengths)),\n",
    "        \"95th_percentile\": int(np.percentile(lengths, 95)),\n",
    "        \"mean\": round(np.mean(lengths), 2),\n",
    "        \"min\": int(np.min(lengths)),\n",
    "        \"num_samples\": len(lengths),\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "# Compute for both splits\n",
    "train_stats = compute_token_stats(formatted_dataset[\"train\"], tokenizer)\n",
    "test_stats = compute_token_stats(formatted_dataset[\"test\"], tokenizer)\n",
    "\n",
    "print(\"Train Token Length Stats:\", train_stats)\n",
    "print(\"Test Token Length Stats:\", test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c89640e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean SQL Response token length: 51.61714834900803\n",
      "95th percentile: 162.0\n",
      "Max SQL Response token length: 1868\n"
     ]
    }
   ],
   "source": [
    "#looking at the max token size in the entire data response\n",
    "sql_token_lengths = df_clean[\"response\"].apply(lambda x: len(tokenizer(x, truncation=False)[\"input_ids\"]))\n",
    "\n",
    "# Analyze\n",
    "print(\"Mean SQL Response token length:\", sql_token_lengths.mean())\n",
    "print(\"95th percentile:\", sql_token_lengths.quantile(0.95))\n",
    "print(\"Max SQL Response token length:\", sql_token_lengths.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce08fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smart Padding\n",
    "def tokenize(examples):\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    max_length = 4096\n",
    "\n",
    "    for full_text in examples[\"text\"]:\n",
    "        # Extract prompt and response\n",
    "        prompt_text = full_text.split(\"### Response:\")[0].strip() + \"\\n### Response:\\n\"\n",
    "        response_text = full_text.split(\"### Response:\")[1].strip()\n",
    "        \n",
    "        # Tokenize with truncation\n",
    "        prompt_tokens = tokenizer(prompt_text, truncation=True, max_length=max_length)[\"input_ids\"]\n",
    "        response_tokens = tokenizer(response_text, truncation=True, max_length=max_length)[\"input_ids\"]\n",
    "        response_tokens.append(tokenizer.eos_token_id)\n",
    "        \n",
    "        # Combine tokens for input\n",
    "        input_ids = prompt_tokens + response_tokens\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        \n",
    "        # Create labels - keep prompt tokens, mask response tokens\n",
    "        labels = input_ids.copy()  # Start with full sequence\n",
    "        labels = [-100] * len(prompt_tokens) + response_tokens #mask prompt tokens\n",
    "\n",
    "        input_ids_list.append(input_ids)\n",
    "        attention_mask_list.append(attention_mask)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids_list,\n",
    "        \"attention_mask\": attention_mask_list,\n",
    "        \"labels\": labels_list\n",
    "    }\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # because this is causal LM\n",
    "    pad_to_multiple_of=16  # speeds up training on GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27c850b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\sidpk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#computing the metrics for the baseline model based on similarilty of output, sql compilation and time\n",
    "\n",
    "# Load metrics\n",
    "meteor_metric = evaluate.load(\"meteor\")\n",
    "\n",
    "def can_execute_sql(generated_sql, schema=None):\n",
    "    \"\"\"Check if a SQL query can be executed against a given schema.\n",
    "    \n",
    "    Args:\n",
    "        generated_sql (str): The SQL query to test\n",
    "        schema (str, optional): The database schema to create before testing\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if the query executes successfully, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(\":memory:\")\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Create schema if provided\n",
    "        if schema:\n",
    "            cursor.executescript(schema)\n",
    "            \n",
    "        # Try to execute the query\n",
    "        cursor.execute(generated_sql)\n",
    "        return True\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"SQL Error: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "def extract_sql_from_output(output_text, prompt_text):\n",
    "    \"\"\"Extract SQL query from model output, handling various formats.\"\"\"\n",
    "    # Remove the prompt from the output\n",
    "    sql_text = output_text[len(prompt_text):].strip()\n",
    "    \n",
    "    # Remove any markdown code blocks if present\n",
    "    sql_text = re.sub(r'```sql\\s*|\\s*```', '', sql_text)\n",
    "    sql_text = re.sub(r'```\\s*|\\s*```', '', sql_text)\n",
    "    \n",
    "    # Remove any trailing text after semicolon\n",
    "    if ';' in sql_text:\n",
    "        sql_text = sql_text.split(';')[0] + ';'\n",
    "    \n",
    "    return sql_text.strip()\n",
    "\n",
    "def evaluate_model_on_dataset(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    dataset,\n",
    "    max_new_tokens=2048\n",
    "):\n",
    "    predictions = []\n",
    "    references = []\n",
    "    compile_success = 0\n",
    "    execution_times = []\n",
    "\n",
    "    dataset_slice = dataset\n",
    "\n",
    "    for example in tqdm(dataset_slice, desc=\"Evaluating\"):\n",
    "        # Extract prompt and response using the same format as tokenize function\n",
    "        prompt_text = example[\"text\"].split(\"### Response:\")[0].strip() + \"\\n### Response:\\n\"\n",
    "        ground_truth = example[\"text\"].split(\"### Response:\")[1].strip()\n",
    "        schema = example[\"text\"].split(\"### Input:\")[1].split(\"### Response:\")[0].strip()\n",
    "\n",
    "        inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "        \n",
    "        # Get the generated SQL - everything after the prompt\n",
    "        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        generated_sql = extract_sql_from_output(decoded, prompt_text)\n",
    "        print(\"SQL Output:\", generated_sql)\n",
    "\n",
    "        # Add prediction for METEOR\n",
    "        predictions.append(generated_sql)\n",
    "        references.append([ground_truth])  # METEOR expects references as a list of lists\n",
    "\n",
    "        # Compile SQL Query and measure time\n",
    "        start_time = time.perf_counter()\n",
    "        success = can_execute_sql(generated_sql, schema)\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        if success:\n",
    "            compile_success += 1\n",
    "            execution_times.append(end_time - start_time)\n",
    "\n",
    "    # Compute metrics\n",
    "    meteor_score = meteor_metric.compute(predictions=predictions, references=references)[\"meteor\"]\n",
    "    sql_compilation_rate = compile_success / len(dataset_slice)\n",
    "    \n",
    "    # Calculate average execution time for successful queries\n",
    "    avg_execution_time = sum(execution_times) / len(execution_times) if execution_times else 0\n",
    "\n",
    "    metrics = {\n",
    "        \"meteor_score\": round(meteor_score, 4),\n",
    "        \"sql_compilation_rate\": round(sql_compilation_rate, 4),\n",
    "        \"avg_execution_time_ms\": round(avg_execution_time * 1000, 2),  # Convert to milliseconds\n",
    "        \"num_eval_samples\": len(dataset_slice),\n",
    "        \"num_successful_queries\": compile_success\n",
    "    }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dc566c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "809c73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting the finetuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff42342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "563b4aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msidpkul21\u001b[0m (\u001b[33msidpkul21-georgia-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sidpk\\Documents\\Deepseek-Finetuning-SQL-Practice\\notebooks\\wandb\\run-20250412_163857-4o3ranjc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sidpkul21-georgia-institute-of-technology/deepseek-sql-finetune/runs/4o3ranjc' target=\"_blank\">baseline-run</a></strong> to <a href='https://wandb.ai/sidpkul21-georgia-institute-of-technology/deepseek-sql-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sidpkul21-georgia-institute-of-technology/deepseek-sql-finetune' target=\"_blank\">https://wandb.ai/sidpkul21-georgia-institute-of-technology/deepseek-sql-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sidpkul21-georgia-institute-of-technology/deepseek-sql-finetune/runs/4o3ranjc' target=\"_blank\">https://wandb.ai/sidpkul21-georgia-institute-of-technology/deepseek-sql-finetune/runs/4o3ranjc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sidpkul21-georgia-institute-of-technology/deepseek-sql-finetune/runs/4o3ranjc?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x267a4933f70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"deepseek-sql-finetune\",\n",
    "    name=\"baseline-run\",\n",
    "    notes=\"1.3B model with QLoRA, loss tracking\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "371be074",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./deepseek-coder-qlora-sql-v2\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    fp16=True,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"deepseek-coder-qlora-sql-run1\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    save_total_limit=3,\n",
    "    label_names=[\"labels\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "617580cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # or [\"query_key_value\"] depending on model architecture\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model_finetune = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce7f2c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da0982a2e584a19ad79206d678aefd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/235985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c89fe189f74376bb31df40b2503a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = formatted_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57040a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sidpk\\AppData\\Local\\Temp\\ipykernel_3000\\2103303720.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "small_train = tokenized_dataset[\"train\"].select(range(10000))\n",
    "small_eval = tokenized_dataset[\"test\"].select(range(1000))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_finetune,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train, \n",
    "    eval_dataset=small_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e076ce18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 3:13:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.844200</td>\n",
       "      <td>0.893414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.708400</td>\n",
       "      <td>0.758137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.636500</td>\n",
       "      <td>0.694039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.600400</td>\n",
       "      <td>0.672734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.563600</td>\n",
       "      <td>0.660649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.565100</td>\n",
       "      <td>0.655386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.544700</td>\n",
       "      <td>0.654213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.7051525970458984, metrics={'train_runtime': 11637.7342, 'train_samples_per_second': 2.578, 'train_steps_per_second': 0.322, 'total_flos': 8.956591972201267e+16, 'train_loss': 0.7051525970458984, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51dc4fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32256, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=2048, out_features=5504, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=2048, out_features=5504, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=5504, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=32256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_finetune.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2622659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\t\n",
    "Below are sql tables schemas paired with instruction that describes a task. Using valid SQLite, write a response that appropriately completes the request for the provided tables. ### Instruction: What model has a launch of September 3, 2010? ### Input: CREATE TABLE table_28269 (\n",
    "\"Model\" text,\n",
    "\"Launch\" text,\n",
    "\"Code name\" text,\n",
    "\"Transistors (million)\" real,\n",
    "\"Die size (mm 2 )\" real,\n",
    "\"Bus interface\" text,\n",
    "\"Memory ( MB )\" text,\n",
    "\"SM count\" real,\n",
    "\"Core config 1,3\" text,\n",
    "\"Core ( MHz )\" real,\n",
    "\"Shader ( MHz )\" real,\n",
    "\"Memory ( MHz )\" text,\n",
    "\"Pixel ( GP /s)\" text,\n",
    "\"Texture ( GT /s)\" text,\n",
    "\"Bandwidth ( GB /s)\" text,\n",
    "\"DRAM type\" text,\n",
    "\"Bus width ( bit )\" real,\n",
    "\"GFLOPS (FMA) 2\" text,\n",
    "\"TDP (watts)\" real,\n",
    "\"Release price (USD)\" text\n",
    ") ### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf6360a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \"model\", COUNT(\"launch\") FROM table_547 WHERE DATETIME(PARSE('September  3 ,   2001' USING 'MMM dd'), PARSE('January    1,' USING '%Y')) = LAUNCH GROUP BY MODEL ORDER BY DESC LIMIT\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model_finetune.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2048,\n",
    "    temperature=0.2,\n",
    "    top_p=0.95,\n",
    "    do_sample=True,\n",
    "    eos_token_id = tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    repetition_penalty=1.2,  # Add repetition penalty\n",
    "    no_repeat_ngram_size=3,  # Prevent repeating 3-grams\n",
    ")\n",
    "\n",
    "generated_sql = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# Extract only the response part (everything after \"### Response:\")\n",
    "generated_sql = generated_sql.split(\"### Response:\")[-1].strip()\n",
    "print(generated_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "323049bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISSES FROM SECOND TRAINING\n",
    "#The training data was not large enough to train the model to its full potential.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ee438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepseek-finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
